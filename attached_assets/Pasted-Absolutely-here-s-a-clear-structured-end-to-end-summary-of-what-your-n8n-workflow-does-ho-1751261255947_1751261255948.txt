Absolutelyâ€”hereâ€™s a **clear, structured, end-to-end summary** of what your **n8n workflow does**, how it is designed, and what weâ€™ve done step by step:

---

# ğŸ“˜ **n8n Workflow: WhatsApp Watch Listings Extraction, Enrichment, and Sheet Append**

---

## ğŸ¯ **Goal**

You are building an automated flow to:

1. **Watch incoming WhatsApp group messages**.
2. **Extract multiple watch listings** from a single message using regex parsing.
3. **Enrich each listing** by cross-referencing a master database (e.g., mapping reference numbers to Brand/Family/Name).
4. **Append enriched rows** to a Google Sheet.
5. Avoid re-processing the same messages.

---

## ğŸ› ï¸ **High-Level Flow**

### âœ… **1) Trigger**

* **Schedule Trigger** runs every X minutes.

---

### âœ… **2) Watch Database Rows**

* Loads **all rows** from a separate Google Sheet containing your **master watch reference database** (e.g., 24,796 rows).
* Example fields per row:

  * Reference: `4600E/000R-B576`
  * Brand: `Vacheron Constantin`
  * Family: `Patrimony`
  * Name: `Manual-Wind`

---

### âœ… **3) Build DB Map**

* **Purpose:**

  * Create a fast lookup map (`byPID`) of all references for O(1) enrichment.
* **How:**

  * For each row:

    * Extract Reference (`Reference`, fallback to `PID`).
    * Normalize to uppercase and trim.
    * Skip numeric-only noise (`119.026`).
    * Store as:

      ```javascript
      byPID["4600E/000R-B576"] = {Brand, Family, Name, Reference,...}
      ```
  * Store `byPID` in **global static data**:

    ```javascript
    const sd = $getWorkflowStaticData('global')
    sd.byPID = byPID
    sd.dbMapReady = true
    sd.lastUpdated = new Date().toISOString()
    ```
* **Outcome:**

  * Efficient enrichment for any listing later in the flow.

---

### âœ… **4) Get Row(s) in Sheet**

* Reads the **log sheet** containing WhatsApp messages (raw).
* Example columns:

  * Timestamp
  * Group ID
  * Sender
  * Message text

---

### âœ… **5) Row Counter Code**

* Filters only **new rows/messages**.
* Maintains:

  * `lastProcessedRow`
  * `processedMessages`
* Avoids reprocessing old messages.

---

### âœ… **6) Regex Parser**

* **Purpose:**

  * Split a single raw message into multiple structured listings.
* **Logic:**

  * Splits message by:

    * Watch symbols (â™¨, â­, etc.).
    * Patterns like â€œRM11-03â€ or reference codes.
  * For each chunk:

    * Extracts fields:

      * `PID` (reference)
      * `Year`
      * `Condition`
      * `Currency`
      * `Price`
      * etc.
* **Output:**

  * **One item per watch listing.**

---

### âœ… **7) Debug Node**

* Prints and verifies the output after Regex.
* Shows:

  * `totalChunks`
  * Each PID
  * Raw Line preview
* **Critical for confirming split worked** (this is what we fixed!).

---

### âœ… **8) Enrich from DB**

* For each listing:

  * Looks up `byPID` using `PID` (uppercase).
  * Enriches with:

    * Brand
    * Family
    * Name
* Adds debug metadata:

  * `_dbLookup`: FOUND or NOT\_FOUND
  * `_debug_cleanPID`
  * `_debug_mapSize`

---

### âœ… **9) Reference Lookup & Formatter**

* Optionally does further processing (e.g., cleaning).
* Formats for Google Sheet append.

---

### âœ… **10) Append to Sheet**

* Appends enriched listings back to your target Google Sheet.

---

---

## ğŸ§­ **What We Have Done and Solved**

Hereâ€™s everything you and I have worked through:

âœ… **1) Static Data Issues**

* Clarified that **global static data (`$getWorkflowStaticData('global')`)** only persists when the workflow runs as a wholeâ€”not when testing nodes one by one.

---

âœ… **2) Execution Order**

* Moved **Watch Database Rows** and **Build DB Map** **before** any enrichment.
* Ensured DB map is populated first.

---

âœ… **3) Debugging**

* Added robust debug nodes:

  * **After Regex Parser**:

    * To confirm correct splitting (Raw Lines, PIDs).
  * **After Enrich Node**:

    * To verify enrichment success and see what PIDs were matched.

---

âœ… **4) Regex Extraction**

* Fixed splitting to handle multiple watch listings.
* Ensured that empty PIDs and numeric noise are filtered out.

---

âœ… **5) DB Map Build**

* Validated that you were indexing thousands of rows and only keeping valid references.

---

âœ… **6) Clarified Node Settings**

* Instructed when to use **Execute Once** or not:

  * Build DB Map: `Execute Once for All Items`
  * Regex Parser: `Execute Once: OFF`
  * Debug Nodes: `Execute Once: ON`

---

âœ… **7) Cleaned Output**

* Added clear enriched data:

  * Brand
  * Family
  * Name
* Verified when enrichment works and when it doesnâ€™t.

---

---

## ğŸ”„ **Example Flow Recap**

To visualize:

```
Schedule Trigger
    â†“
Watch Database Rows
    â†“
Build DB Map   â† stores {byPID} globally
    â†“
Get Sheet Rows (Raw WhatsApp Messages)
    â†“
Row Counter Code (only new rows)
    â†“
Regex Parser (split message into listings)
    â†“
Debug Node (confirm split)
    â†“
Enrich from DB (add brand/family/name)
    â†“
Reference Lookup & Format
    â†“
Append to Sheet
```

---

## ğŸ§© **Whatâ€™s Left or Next Steps**

Hereâ€™s what you can consider doing further:
âœ… Confirm your master DB sheet contains **clean, uppercase references**.
âœ… Optionally save logs of all enriched messages.
âœ… Possibly add a filter node to exclude items with no PID.
âœ… Automate running every few minutes.

---

## ğŸ‰ **Summary in One Sentence**

**You have a robust pipeline that reads raw WhatsApp messages, splits them into structured watch listings, enriches each listing from your master database, and appends the enriched data to your sheetâ€”avoiding duplicates and logging everything.**

---

If you want, I can help you:

* Tweak Regex extraction further.
* Improve enrichment fallback logic.
* Polish final append formatting.
  Just let me know!
